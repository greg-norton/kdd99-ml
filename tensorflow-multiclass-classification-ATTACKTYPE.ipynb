{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 22544 rows.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #path = get_file('kddcup.data.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz')\n",
    "    #path = get_file('kddcup.data_10_percent.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz')\n",
    "    path = './nslkdd/KDDTest+.txt'\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "    \n",
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome',\n",
    "    'difficulty_rating'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "apache2             737\n",
      "back                359\n",
      "buffer_overflow      20\n",
      "ftp_write             3\n",
      "guess_passwd       1231\n",
      "httptunnel          133\n",
      "imap                  1\n",
      "ipsweep             141\n",
      "land                  7\n",
      "loadmodule            2\n",
      "mailbomb            293\n",
      "mscan               996\n",
      "multihop             18\n",
      "named                17\n",
      "neptune            4657\n",
      "nmap                 73\n",
      "normal             9711\n",
      "perl                  2\n",
      "phf                   2\n",
      "pod                  41\n",
      "portsweep           157\n",
      "processtable        685\n",
      "ps                   15\n",
      "rootkit              13\n",
      "saint               319\n",
      "satan               735\n",
      "sendmail             14\n",
      "smurf               665\n",
      "snmpgetattack       178\n",
      "snmpguess           331\n",
      "sqlattack             2\n",
      "teardrop             12\n",
      "udpstorm              2\n",
      "warezmaster         944\n",
      "worm                  2\n",
      "xlock                 9\n",
      "xsnoop                4\n",
      "xterm                13\n",
      "Name: outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('outcome')['outcome'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos       3883370\n",
      "normal     972781\n",
      "probe       41102\n",
      "r2l          1126\n",
      "u2r            52\n",
      "Name: outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DOS_TYPES = ('back','land','neptune','pod','smurf','teardrop')\n",
    "U2R_TYPES = ('buffer_overflow','loadmodule','perl','rootkit')\n",
    "R2L_TYPES = ('ftp_write','guess_passwd','imap','multihop','phf','spy','warezclient','warezmaster')\n",
    "PROBE_TYPES = ('ipsweep','nmap','portsweep','satan')\n",
    "        \n",
    "for i, row in df.iterrows():\n",
    "    val = 'normal'\n",
    "    old_val = row['outcome'].split('.')[0]\n",
    "    if old_val in DOS_TYPES:\n",
    "        val = 'dos'\n",
    "    elif old_val in U2R_TYPES:\n",
    "        val = 'u2r'\n",
    "    elif old_val in R2L_TYPES:\n",
    "        val = 'r2l'\n",
    "    elif old_val in PROBE_TYPES:\n",
    "        val = 'probe'\n",
    "    df.at[i,'outcome'] = val       \n",
    "        \n",
    "print(df['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "encode_text_dummy(df, 'is_host_login')\n",
    "encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "df[0:5]\n",
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "\n",
    "df_trainer = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 0\n",
    "while num_classes != 5: ###I need a sample that contains all the types of attacks, otherwise I cannot classify some of them\n",
    "\n",
    "    df_trainer = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "    \n",
    "    # Convert to numpy - Classification\n",
    "    x_columns = df_trainer.columns.drop('outcome')\n",
    "    x = df_trainer[x_columns].values\n",
    "    dummies = pd.get_dummies(df_trainer['outcome']) # Classification\n",
    "    #dummies = pd.get_dummies(df['outcome']) # Classification\n",
    "\n",
    "    outcomes = dummies.columns\n",
    "    num_classes = len(outcomes)\n",
    "    y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "dos       388581\n",
      "normal     97091\n",
      "probe       4055\n",
      "r2l          113\n",
      "u2r            3\n",
      "Name: outcome, dtype: int64\n",
      "         duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
      "1411921 -0.066833  -0.001949  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "4722504 -0.066833  -0.001949  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "179688  -0.066833  -0.001691   0.000238       -0.015139 -0.001103 -0.026521   \n",
      "14919   -0.066833  -0.001623  -0.001165       -0.015139 -0.001103 -0.026521   \n",
      "999082  -0.066833  -0.000853  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "\n",
      "         num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
      "1411921          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "4722504          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "179688           -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "14919            -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "999082           -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "\n",
      "         flag-SF  flag-SH  land-0  land-1  logged_in-0  logged_in-1  \\\n",
      "1411921        0        0       1       0            1            0   \n",
      "4722504        0        0       1       0            1            0   \n",
      "179688         1        0       1       0            0            1   \n",
      "14919          1        0       1       0            0            1   \n",
      "999082         1        0       1       0            1            0   \n",
      "\n",
      "         is_host_login-0  is_host_login-1  is_guest_login-0  is_guest_login-1  \n",
      "1411921                1                0                 1                 0  \n",
      "4722504                1                0                 1                 0  \n",
      "179688                 1                0                 1                 0  \n",
      "14919                  1                0                 1                 0  \n",
      "999082                 1                0                 1                 0  \n",
      "\n",
      "[5 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_trainer.groupby('outcome')['outcome'].count())\n",
    "print(df_trainer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(64,64,),max_iter=50,verbose=True)\n",
    "#mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#predictions = mlp.predict(x_test)\n",
    "#print(confusion_matrix(y_test, predictions))\n",
    "#print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3673823 samples, validate on 1224608 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "estimator.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "pred = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "Validation score: 0.9992977356056214\n"
     ]
    }
   ],
   "source": [
    "y_eval = np.argmax(y_test, axis=1)\n",
    "print(y_eval)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('outcome')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['outcome']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "y = dummies.values\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for entire dataset: 0.9992760947331911\n"
     ]
    }
   ],
   "source": [
    "y_eval_full = np.argmax(y, axis=1)\n",
    "full_pred = estimator.predict(x)\n",
    "score = metrics.accuracy_score(y_eval_full, full_pred)\n",
    "print(\"Validation score for entire dataset: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
