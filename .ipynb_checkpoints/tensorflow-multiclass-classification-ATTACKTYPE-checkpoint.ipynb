{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 494021 rows.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    path = get_file('kddcup.data.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz')\n",
    "    #path = get_file('kddcup.data_10_percent.gz', origin='http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz')\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "    \n",
    "df = pd.read_csv(path, header=None)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "\n",
    "df.dropna(inplace=True,axis=1) # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "\n",
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'outcome'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos       391458\n",
      "normal     97278\n",
      "probe       4107\n",
      "r2l         1126\n",
      "u2r           52\n",
      "Name: outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DOS_TYPES = ('back','land','neptune','pod','smurf','teardrop')\n",
    "U2R_TYPES = ('buffer_overflow','loadmodule','perl','rootkit')\n",
    "R2L_TYPES = ('ftp_write','guess_passwd','imap','multihop','phf','spy','warezclient','warezmaster')\n",
    "PROBE_TYPES = ('ipsweep','nmap','portsweep','satan')\n",
    "        \n",
    "for i, row in df.iterrows():\n",
    "    val = 'normal'\n",
    "    old_val = row['outcome'].split('.')[0]\n",
    "    if old_val in DOS_TYPES:\n",
    "        val = 'dos'\n",
    "    elif old_val in U2R_TYPES:\n",
    "        val = 'u2r'\n",
    "    elif old_val in R2L_TYPES:\n",
    "        val = 'r2l'\n",
    "    elif old_val in PROBE_TYPES:\n",
    "        val = 'probe'\n",
    "    df.at[i,'outcome'] = val       \n",
    "        \n",
    "print(df['outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now encode the feature vector\n",
    "\n",
    "encode_numeric_zscore(df, 'duration')\n",
    "encode_text_dummy(df, 'protocol_type')\n",
    "encode_text_dummy(df, 'service')\n",
    "encode_text_dummy(df, 'flag')\n",
    "encode_numeric_zscore(df, 'src_bytes')\n",
    "encode_numeric_zscore(df, 'dst_bytes')\n",
    "encode_text_dummy(df, 'land')\n",
    "encode_numeric_zscore(df, 'wrong_fragment')\n",
    "encode_numeric_zscore(df, 'urgent')\n",
    "encode_numeric_zscore(df, 'hot')\n",
    "encode_numeric_zscore(df, 'num_failed_logins')\n",
    "encode_text_dummy(df, 'logged_in')\n",
    "encode_numeric_zscore(df, 'num_compromised')\n",
    "encode_numeric_zscore(df, 'root_shell')\n",
    "encode_numeric_zscore(df, 'su_attempted')\n",
    "encode_numeric_zscore(df, 'num_root')\n",
    "encode_numeric_zscore(df, 'num_file_creations')\n",
    "encode_numeric_zscore(df, 'num_shells')\n",
    "encode_numeric_zscore(df, 'num_access_files')\n",
    "encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "encode_text_dummy(df, 'is_host_login')\n",
    "encode_text_dummy(df, 'is_guest_login')\n",
    "encode_numeric_zscore(df, 'count')\n",
    "encode_numeric_zscore(df, 'srv_count')\n",
    "encode_numeric_zscore(df, 'serror_rate')\n",
    "encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'rerror_rate')\n",
    "encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "encode_numeric_zscore(df, 'same_srv_rate')\n",
    "encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_count')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "df[0:5]\n",
    "# This is the numeric feature vector, as it goes to the neural net\n",
    "\n",
    "df_trainer = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 0\n",
    "while num_classes != 5: ###I need a sample that contains all the types of attacks, otherwise I cannot classify some of them\n",
    "\n",
    "    df_trainer = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "    \n",
    "    # Convert to numpy - Classification\n",
    "    x_columns = df_trainer.columns.drop('outcome')\n",
    "    x = df_trainer[x_columns].values\n",
    "    dummies = pd.get_dummies(df_trainer['outcome']) # Classification\n",
    "    #dummies = pd.get_dummies(df['outcome']) # Classification\n",
    "\n",
    "    outcomes = dummies.columns\n",
    "    num_classes = len(outcomes)\n",
    "    y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "dos       39052\n",
      "normal     9817\n",
      "probe       420\n",
      "r2l         110\n",
      "u2r           3\n",
      "Name: outcome, dtype: int64\n",
      "         duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
      "233445  -0.067792  -0.002017  -0.026287        -0.04772 -0.002571 -0.044136   \n",
      "44132   -0.067792  -0.002017  -0.026287        -0.04772 -0.002571 -0.044136   \n",
      "201445  -0.067792  -0.002017  -0.026287        -0.04772 -0.002571 -0.044136   \n",
      "397565  -0.067792  -0.002535  -0.026287        -0.04772 -0.002571 -0.044136   \n",
      "146846  10.954517  -0.002913  -0.023109        -0.04772 -0.002571 -0.044136   \n",
      "\n",
      "        num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
      "233445          -0.009782        -0.005679   -0.010552     -0.004676  ...   \n",
      "44132           -0.009782        -0.005679   -0.010552     -0.004676  ...   \n",
      "201445          -0.009782        -0.005679   -0.010552     -0.004676  ...   \n",
      "397565          -0.009782        -0.005679   -0.010552     -0.004676  ...   \n",
      "146846          -0.009782        -0.005679   -0.010552     -0.004676  ...   \n",
      "\n",
      "        flag-S3  flag-SF  flag-SH  land-0  land-1  logged_in-0  logged_in-1  \\\n",
      "233445        0        1        0       1       0            1            0   \n",
      "44132         0        1        0       1       0            1            0   \n",
      "201445        0        1        0       1       0            1            0   \n",
      "397565        0        1        0       1       0            1            0   \n",
      "146846        0        1        0       1       0            1            0   \n",
      "\n",
      "        is_host_login-0  is_guest_login-0  is_guest_login-1  \n",
      "233445                1                 1                 0  \n",
      "44132                 1                 1                 0  \n",
      "201445                1                 1                 0  \n",
      "397565                1                 1                 0  \n",
      "146846                1                 1                 0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_trainer.groupby('outcome')['outcome'].count())\n",
    "print(df_trainer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=x.shape[1], activation='linear'))\n",
    "    model.add(Dense(32, input_dim=x.shape[1], activation='linear'))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(64,64,),max_iter=50,verbose=True)\n",
    "#mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#predictions = mlp.predict(x_test)\n",
    "#print(confusion_matrix(y_test, predictions))\n",
    "#print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37051 samples, validate on 12351 samples\n",
      "Epoch 1/50\n",
      "37051/37051 - 36s - loss: 0.0867 - accuracy: 0.9803 - val_loss: 0.0232 - val_accuracy: 0.9951\n",
      "Epoch 2/50\n",
      "37051/37051 - 38s - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0173 - val_accuracy: 0.9968\n",
      "Epoch 3/50\n",
      "37051/37051 - 33s - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0159 - val_accuracy: 0.9979\n",
      "Epoch 4/50\n",
      "37051/37051 - 37s - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.0165 - val_accuracy: 0.9972\n",
      "Epoch 5/50\n",
      "37051/37051 - 39s - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0146 - val_accuracy: 0.9979\n",
      "Epoch 6/50\n",
      "37051/37051 - 42s - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0182 - val_accuracy: 0.9971\n",
      "Epoch 7/50\n",
      "37051/37051 - 39s - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0179 - val_accuracy: 0.9980\n",
      "Epoch 8/50\n",
      "37051/37051 - 37s - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0163 - val_accuracy: 0.9977\n",
      "Epoch 9/50\n",
      "37051/37051 - 41s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0150 - val_accuracy: 0.9981\n",
      "Epoch 10/50\n",
      "37051/37051 - 38s - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0130 - val_accuracy: 0.9985\n",
      "Epoch 11/50\n",
      "37051/37051 - 36s - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0260 - val_accuracy: 0.9981\n",
      "Epoch 12/50\n",
      "37051/37051 - 36s - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0221 - val_accuracy: 0.9981\n",
      "Epoch 13/50\n",
      "37051/37051 - 33s - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0187 - val_accuracy: 0.9982\n",
      "Epoch 14/50\n",
      "37051/37051 - 37s - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0230 - val_accuracy: 0.9980\n",
      "Epoch 15/50\n",
      "37051/37051 - 39s - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0218 - val_accuracy: 0.9981\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2040c828d08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "estimator.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "pred = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "Validation score: 0.9980568375030362\n"
     ]
    }
   ],
   "source": [
    "y_eval = np.argmax(y_test, axis=1)\n",
    "print(y_eval)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('outcome')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['outcome']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "y = dummies.values\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score for entire dataset: 0.9984656522698427\n"
     ]
    }
   ],
   "source": [
    "y_eval_full = np.argmax(y, axis=1)\n",
    "full_pred = estimator.predict(x)\n",
    "score = metrics.accuracy_score(y_eval_full, full_pred)\n",
    "print(\"Validation score for entire dataset: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
