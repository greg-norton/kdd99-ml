{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "FULL_DATASET = 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz'\n",
    "TEN_PERCENT_DATASET = 'http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kdd99_df(df):\n",
    "    length = len(df)\n",
    "    print('Processing {} rows'.format(length))\n",
    "    df.columns = [\n",
    "        'duration',\n",
    "        'protocol_type',\n",
    "        'service',\n",
    "        'flag',\n",
    "        'src_bytes',\n",
    "        'dst_bytes',\n",
    "        'land',\n",
    "        'wrong_fragment',\n",
    "        'urgent',\n",
    "        'hot',\n",
    "        'num_failed_logins',\n",
    "        'logged_in',\n",
    "        'num_compromised',\n",
    "        'root_shell',\n",
    "        'su_attempted',\n",
    "        'num_root',\n",
    "        'num_file_creations',\n",
    "        'num_shells',\n",
    "        'num_access_files',\n",
    "        'num_outbound_cmds',\n",
    "        'is_host_login',\n",
    "        'is_guest_login',\n",
    "        'count',\n",
    "        'srv_count',\n",
    "        'serror_rate',\n",
    "        'srv_serror_rate',\n",
    "        'rerror_rate',\n",
    "        'srv_rerror_rate',\n",
    "        'same_srv_rate',\n",
    "        'diff_srv_rate',\n",
    "        'srv_diff_host_rate',\n",
    "        'dst_host_count',\n",
    "        'dst_host_srv_count',\n",
    "        'dst_host_same_srv_rate',\n",
    "        'dst_host_diff_srv_rate',\n",
    "        'dst_host_same_src_port_rate',\n",
    "        'dst_host_srv_diff_host_rate',\n",
    "        'dst_host_serror_rate',\n",
    "        'dst_host_srv_serror_rate',\n",
    "        'dst_host_rerror_rate',\n",
    "        'dst_host_srv_rerror_rate',\n",
    "        'outcome'\n",
    "    ]\n",
    "    df.dropna(inplace=True,axis=1)\n",
    "    print('{} fields dropped due to missing data.'.format(length-len(df)))\n",
    "    print('{} unique outcomes present (should be 23 for KDD99)'.format(df['outcome'].nunique()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "def download_to_df(url):\n",
    "    try:\n",
    "        path = get_file(url.split('/')[-1], origin=url)\n",
    "    except:\n",
    "        print('Error downloading dataset')\n",
    "        raise\n",
    "    return pd.read_csv(path, header=None)\n",
    "\n",
    "def generate_training_set(df, frac=0.1, num_outcomes=23):\n",
    "    trainer = None\n",
    "    while (trainer is None or trainer['outcome'].nunique() != num_outcomes):\n",
    "        trainer = df.sample(frac=frac, replace=False)\n",
    "    return trainer\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "def encode_kdd99_df(df):\n",
    "    length = len(df)\n",
    "    \n",
    "    encode_numeric_zscore(df, 'duration')\n",
    "    encode_text_dummy(df, 'protocol_type')\n",
    "    encode_text_dummy(df, 'service')\n",
    "    encode_text_dummy(df, 'flag')\n",
    "    encode_numeric_zscore(df, 'src_bytes')\n",
    "    encode_numeric_zscore(df, 'dst_bytes')\n",
    "    encode_text_dummy(df, 'land')\n",
    "    encode_numeric_zscore(df, 'wrong_fragment')\n",
    "    encode_numeric_zscore(df, 'urgent')\n",
    "    encode_numeric_zscore(df, 'hot')\n",
    "    encode_numeric_zscore(df, 'num_failed_logins')\n",
    "    encode_text_dummy(df, 'logged_in')\n",
    "    encode_numeric_zscore(df, 'num_compromised')\n",
    "    encode_numeric_zscore(df, 'root_shell')\n",
    "    encode_numeric_zscore(df, 'su_attempted')\n",
    "    encode_numeric_zscore(df, 'num_root')\n",
    "    encode_numeric_zscore(df, 'num_file_creations')\n",
    "    encode_numeric_zscore(df, 'num_shells')\n",
    "    encode_numeric_zscore(df, 'num_access_files')\n",
    "    encode_numeric_zscore(df, 'num_outbound_cmds')\n",
    "    encode_text_dummy(df, 'is_host_login')\n",
    "    encode_text_dummy(df, 'is_guest_login')\n",
    "    encode_numeric_zscore(df, 'count')\n",
    "    encode_numeric_zscore(df, 'srv_count')\n",
    "    encode_numeric_zscore(df, 'serror_rate')\n",
    "    encode_numeric_zscore(df, 'srv_serror_rate')\n",
    "    encode_numeric_zscore(df, 'rerror_rate')\n",
    "    encode_numeric_zscore(df, 'srv_rerror_rate')\n",
    "    encode_numeric_zscore(df, 'same_srv_rate')\n",
    "    encode_numeric_zscore(df, 'diff_srv_rate')\n",
    "    encode_numeric_zscore(df, 'srv_diff_host_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_count')\n",
    "    encode_numeric_zscore(df, 'dst_host_srv_count')\n",
    "    encode_numeric_zscore(df, 'dst_host_same_srv_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_diff_srv_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_same_src_port_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_srv_diff_host_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_serror_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_srv_serror_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_rerror_rate')\n",
    "    encode_numeric_zscore(df, 'dst_host_srv_rerror_rate')\n",
    "    \n",
    "    df.dropna(inplace=True, axis=1)\n",
    "    print('{} rows dropped due to incomplete data'.format(length - len(df)))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4898431 rows\n",
      "0 fields dropped due to missing data.\n",
      "23 unique outcomes present \\(should be 23 for KDD99\\)\n",
      "Processing 494021 rows\n",
      "0 fields dropped due to missing data.\n",
      "23 unique outcomes present \\(should be 23 for KDD99\\)\n"
     ]
    }
   ],
   "source": [
    "df = download_to_df(FULL_DATASET)\n",
    "df_10 = download_to_df(TEN_PERCENT_DATASET)\n",
    "\n",
    "df = process_kdd99_df(df)\n",
    "df_10 = process_kdd99_df(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-bc18e08324ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_training_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-a6c80631e6e0>\u001b[0m in \u001b[0;36mgenerate_training_set\u001b[1;34m(df, frac, num_outcomes)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outcome'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_outcomes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4970\u001b[0m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4971\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4973\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3604\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3605\u001b[0m         )\n\u001b[0;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m             \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m         )\n\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_trainer = generate_training_set(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8ac38188dc44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m###I need a sample that contains all the types of attacks, otherwise I cannot classify some of them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Uncomment this line to sample only 10% of the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_trainer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outcome'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4970\u001b[0m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4971\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4973\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3604\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3605\u001b[0m         )\n\u001b[0;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m             \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m         )\n\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Machine Learning\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 0\n",
    "while num_classes != 23: ###I need a sample that contains all the types of attacks, otherwise I cannot classify some of them\n",
    "\n",
    "    df_trainer = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    "    \n",
    "    dummies = pd.get_dummies(df_trainer['outcome']) # Classification\n",
    "    outcomes = dummies.columns\n",
    "    num_classes = len(outcomes)\n",
    "    \n",
    "# Convert to numpy - Classification\n",
    "x_columns = df_trainer.columns.drop('outcome')\n",
    "x = df_trainer[x_columns].values\n",
    "\n",
    "y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "back.                  229\n",
      "buffer_overflow.         4\n",
      "ftp_write.               1\n",
      "guess_passwd.            5\n",
      "imap.                    2\n",
      "ipsweep.              1308\n",
      "land.                    1\n",
      "multihop.                2\n",
      "neptune.            106864\n",
      "nmap.                  228\n",
      "normal.              97127\n",
      "pod.                    21\n",
      "portsweep.            1092\n",
      "satan.                1609\n",
      "smurf.              281161\n",
      "spy.                     1\n",
      "teardrop.               95\n",
      "warezclient.            90\n",
      "warezmaster.             3\n",
      "Name: outcome, dtype: int64\n",
      "         duration  src_bytes  dst_bytes  wrong_fragment    urgent       hot  \\\n",
      "4081094 -0.066833  -0.001396  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "4676900 -0.066833  -0.001949  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "4622669 -0.066833  -0.001949  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "3948765 -0.066833  -0.001396  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "1722296 -0.066833  -0.000853  -0.001696       -0.015139 -0.001103 -0.026521   \n",
      "\n",
      "         num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
      "4081094          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "4676900          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "4622669          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "3948765          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "1722296          -0.004391        -0.002097   -0.008258     -0.004546  ...   \n",
      "\n",
      "         flag-SF  flag-SH  land-0  land-1  logged_in-0  logged_in-1  \\\n",
      "4081094        1        0       1       0            1            0   \n",
      "4676900        0        0       1       0            1            0   \n",
      "4622669        0        0       1       0            1            0   \n",
      "3948765        1        0       1       0            1            0   \n",
      "1722296        1        0       1       0            1            0   \n",
      "\n",
      "         is_host_login-0  is_host_login-1  is_guest_login-0  is_guest_login-1  \n",
      "4081094                1                0                 1                 0  \n",
      "4676900                1                0                 1                 0  \n",
      "4622669                1                0                 1                 0  \n",
      "3948765                1                0                 1                 0  \n",
      "1722296                1                0                 1                 0  \n",
      "\n",
      "[5 rows x 126 columns]\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(df_trainer.groupby('outcome')['outcome'].count())\n",
    "print(df_trainer.head())\n",
    "print(df['outcome'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(y.shape[1], activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(64,64,),max_iter=50,verbose=True)\n",
    "#mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#predictions = mlp.predict(x_test)\n",
    "#print(confusion_matrix(y_test, predictions))\n",
    "#print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ProgbarLogger\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "progress = ProgbarLogger(count_mode='steps')\n",
    "estimator.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,progress],verbose=2,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "pred = estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = np.argmax(y_test, axis=1)\n",
    "print(y_eval)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('outcome')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['outcome']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "y = dummies.values\n",
    "\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_full = np.argmax(y, axis=1)\n",
    "full_pred = estimator.predict(x)\n",
    "score = metrics.accuracy_score(y_eval_full, full_pred)\n",
    "print(\"Validation score for entire dataset: {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
